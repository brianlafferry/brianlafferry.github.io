<html>
<head>
	<title>XOR Neural Network</title>
</head>
<body>
	<h4>XOR Neural Network (at least my understanding)</h4>
	This is great stuff, too bad it's a step toward a destination rather than a solution.  What's really needed is Elman Recurrent Neural Network.  
	But that's an extention of this Feed Forward Back Propigation network, so you must understand this to start recurrent networks.  And here's the downfall of this one.
	Lets say you built a network to predict the market.  You want to put in the percent price change of minute data.
	<table border=1>
		<tr> <th>Last Minute</th> <th>This Minute</th></tr>
		<tr> <td>2.1</td> <td>3.6</td></tr>
		<tr> <td>2.4</td> <td>3.2</td></tr>
		<tr> <td>2.3</td> <td>1.7</td></tr>
		<tr> <td>2.1</td> <td>2.7</td></tr>
	</table>
	When this network sees 2.1 the first time, it will adjust weights to associate 2.1 to 3.6.  When it sees the last 2.1, it will begin trying to associate 2.1 with 2.7.  
	A Elman Recurrent Neural Network has an additional layer called a <i>context</i> layer so it can know that 2.1 can be associated with 3.6 sometimes, but at other times associated with 2.7.  
	Except for this extra layer, there really isn't much difference between Feed Forward and Elman Recurrent networks.
	
	<p>The meaning (in C) of xor (exclusive OR) means either or, not both, and not neither.  It uses the following truth table <br> <br>
	<table align="center" border=1>
		<tr><th>Inputs</th> <th>Outputs</th><th></th></tr>
		<tr><td> <table align="center"><tr><td>0</td><td>0</td></tr></table></td> <td align="center"> 0 </td><td>Not neither</td></tr>
		<tr><td> <table align="center"><tr><td>1</td><td>0</td></tr></table></td> <td align="center"> 1 </td><td>Either one</td></tr>
		<tr><td> <table align="center"><tr><td>0</td><td>1</td></tr></table></td> <td align="center"> 1 </td><td>Or the other</td></tr>
		<tr><td> <table align="center"><tr><td>1</td><td>1</td></tr></table></td> <td align="center"> 0 </td><td>Not both</td></tr>
	</table>
	</p>
	<p>
		To represent XOR in a neural network, there would be 2 inputs, 1 output and 1 hidden layer <br> <br>
		 <table> <tr> <td align="center"> Per the truth table, an input of 1 and 1 should output 0 </td> <td align="center"> <img src="net1.png" height=400> </td></tr> </table>
	</p>
	<p>
		Lets clarify variable names
		<table border=1>
			<tr><td>Output Value </td><td>Calculated Output Value</td></tr>
			<tr><td>Target Value </td><td>Expected Output Value</td></tr>
		
			<tr><td>O<sub>1 sum</sub>  </td><td>Output by output Neuron</td></tr>
			<tr><td>f'(O<sub>1</sub>)  </td><td>Derivative of Output Neuron output</td></tr>

			<tr><td>H<sub>1 Sum</sub>  </td><td>Hidden layer upper neuron output</td></tr>
			<tr><td>f'(H<sub>1 Out</sub>)  </td><td>Derivative of hidden layer upper neuron output</td></tr>
			<tr><td>HW<sub>1</sub> </td><td>Hidden layer weight </td></tr>
		
			<tr><td>H<sub>2 Sum</sub> </td><td>Hidden layer middle neuron output</td></tr>
			<tr><td>f'(H<sub>2 Out</sub>) </td><td>Derivative of hidden layer middle neuron output</td></tr>
			<tr><td>HW<sub>2</sub> </td><td>Hidden layer middle neuron weight </td></tr>
		
			<tr><td>H<sub>3 Sum</sub>  </td><td>Hidden layer lower neuron </td></tr>
			<tr><td>f'(H<sub>3 Out</sub>) </td><td> Derivative of hidden layer lower neuron output</td></tr>
			<tr><td>HW<sub>3</sub> </td><td> Hidden layer lower neuron weight</td></tr> 
		
			<tr><td>IW<sub>1</sub>  </td><td>Input neuron 1 weight </td></tr>
			<tr><td>IW<sub>2</sub>  </td><td>Input neuron 2 weight </td></tr>
			<tr><td>IW<sub>3</sub>  </td><td>Input neuron 3 weight </td></tr>
			<tr><td>IW<sub>4</sub>  </td><td>Input neuron 4 weight </td></tr>
			<tr><td>IW<sub>5</sub>  </td><td>Input neuron 5 weight </td></tr>
			<tr><td>IW<sub>6</sub>  </td><td>Input neuron 6 weight </td></tr>
		
			<tr><td>I<sub>1</sub> </td><td>Input 1 </td></tr>
			<tr><td>I<sub>2</sub> </td> <td>Input 2</td> </tr>
		
		
		</td></tr> </table>
	</p>
	<p>Since I'm a programmer more than a mathmatician, I'll explain more in code than math<br>
	I saved the following code in the file <i>sig1.c</i> <br>
	And compiled it with <i>gcc -o sig1.exe sig1.c -lm</i>
	</p>
	<p>
		<pre>
#include &lt;stdio.h>
#include &lt;math.h>

int main(void)
{
double in = -4.01 ;
double out = 0 ;
double sigderivative = 0 ;
	
	out = 1.0/(1.0 + exp(-in));         /* Out = Sigmoid(in) */
	
	printf("in = %lf Out = %lf\n", in, out) ;
	
	sigderivative = out * (1.0 - out) ;
	printf("Sigmoid Derivative = %lf\n", sigderivative) ;


return 0 ;
}

		</pre>
		Quick and simple, the code takes the <i>sigmoid</i> of the <i>in</i> variable, and stores it in variable <i>out</i><br>
		It then takes the derivative of <i>out</i>
		<pre>
[localhost neural]$ ./sig1.exe
in = -4.010000 Out = 0.017810
Sigmoid Derivative = 0.017493
		</pre>
	</p>
	<hr>
	<p align="center">Forward Propagation</p>
	<hr>
	<p>
		 <table> <tr> <td align="center"> Starting the network with random weights between 0 and 1 </td> <td align="center"> <img src="net2.png" height=400> </td></tr> </table>
	</p>	
	<p>
	For each layer in the hidden layer, add the inputs * weight
	<pre>
(1 * 0.8) + (1 * 0.2) = 1
(1 * 0.4) + (1 * 0.9) = 1.3
(1 * 0.3) + (1 * 0.5) = 0.8	
	</pre>
	Taking the sigmoid(<i>S</i>) for each of these gives the values of the hidden layer (rounded)
	<table> <tr> <td align="center"> 
		<table>
			<tr><td>S(1)  </td> <td> = 0.731059</td></tr>
			<tr><td>S(1.3)  </td> <td> = 0.785835</td></tr>
			<tr><td>S(0.8)  </td> <td> = 0.689974</td></tr>
		</table>
	</td> <td align="center"> <img src="net3.png" height=400> </td></tr> </table>
	</p>
	<p>
	Again, multiply the values of the hidden layer by the second set of weights, and take the <i>S</i>igmoid<br><br>
	https://stevenmiller888.github.io/mind-how-to-build-a-neural-network/<br><br>
	<pre>
(0.731059*0.3)+(0.785835*0.5)+(0.689974*0.9) = 1.233212
S(1.233212) = 0.774380
	</pre>
	
	On the first pass, the network predicted the answer 0.77<br>
	Per the above truth table, the correct answer should be 0<br>
	<img src="net4.png" height=400>
	</p>
	
	<hr>
	<p align="center">Gradient Descent</p>
	<hr>
	<p>
	To get the correct answer, one would need to adjust the weights, but the question is adjust which weights?  How much?  And in what direction?
	One solution could be brute force, just guess at weight values until the correct (or more correct) answer comes out.
	The problem with brute force is the <i>curse of dimensionality</i>.  
	Because there are an infinite number of weight values for each synapse, one idea might be to limit the number of weights, say guess 1000 weights, then pick the one that came closest to the target.
	But because we need a total of 6 weights to get to the hidden layer, now we need to guess 1000<sup>1000</sup> (1,000,000) weights to test all of them.  
	What if there were 10 inputs, with 20 hidden layers?  The problem grows exponentially with more layers, inputs, and outputs.
	</p>
	The solution is <i>gradient descent</i>, borrowing from the linear regression camp how to calculate errors.  This provides a mathmatical means of calculating the error, and adjusting the weights accordingly.
	<p>
	If you were to guess at an untold number of weights, and graphed the error for each weight (on a single neuron) it would look something like this.  But there are some problems with this.<br>
	1.  You have eyes and can easily see the lowest point on the graph <br>
	2.  A computer doesn't have eyes
	<br><img src="grad1.png" height=400><br>
	Assume you didn't randomly pick the lowest point, and odds are you never will.  You would pick a random point, like the image below.  You would want to find the <i>gradient</i>, or slope (AKA derivative), of the tangent line.  (A tangent line is a straight line that touches a function at only one point.  The tangent line represents the instantaneous rate of change of the function at that one point.)
	<table><tr> <td> <img src="grad2.png" height=400> </td> <td>Note, Sometimes the network will work toward a local minimum instead of the global minimum</td> </tr></table>
	<i>Gradients</i> are usually kept in an array.  This network has 9 weights, so the array needs to be of length 9, one gradient for each weight.
	</p>
	<hr>
	<p align="center">Back Propagation</p>
	<hr>
	<p>
	</p>
	<p>
		Back propagation is very similar to forward, only backwards<br>
		
		Output Value = 0.774380<br>
		Target Value = 0 <br><br>
		
		O<sub>1 sum</sub> = 1.233212 <br>
		f'(O<sub>1</sub>) = 0.774380 <br><br>

		H<sub>1 Sum</sub> = 1 <br>
		f'(H<sub>1 Out</sub>) = 0.731059 <br>
		HW<sub>1</sub> = 0.3<br><br>
		
		H<sub>2 Sum</sub> = 1.3 <br>
		f'(H<sub>2 Out</sub>) = 0.785835 <br>
		HW<sub>2</sub> = 0.5 <br><br>
		
		H<sub>3 Sum</sub> = 0.8 <br>
		f'(H<sub>3 Out</sub>) = 0.689974 <br>
		HW<sub>3</sub> = 0.9 <br><br>
		
		IW<sub>1</sub> = 0.8 <br>
		IW<sub>2</sub> = 0.4 <br>
		IW<sub>3</sub> = 0.3 <br>
		IW<sub>4</sub> = 0.2 <br>
		IW<sub>5</sub> = 0.9 <br>
		IW<sub>6</sub> = 0.5 <br><br>
		
		I<sub>1</sub> = 1 <br>
		I<sub>2</sub> = 1 <br> <br>
	</p>
	
	
	https://www.youtube.com/watch?v=p1-FiWjThs8&t=26s<br><br>
	
	Output Sum Margin of Error = O<sub>E</sub> = expected value - calculated value <br>
	O<sub>E</sub> = 0 - 0.774380 <br> <br>
	
	O<sub>sum</sub> = (H<sub>1 out</sub> * HW<sub>1</sub>) + (H<sub>2 out</sub> * HW<sub>2</sub>) + (H<sub>3 out</sub> * HW<sub>3</sub> <br>
	(0.731059*0.3)+(0.785835*0.5)+(0.689974*0.9) = 1.233212 <br>
	0.219318 + 0.392917 + 0.620977 = 1.233212 <br>
	O<sub>sum</sub> = 1.233212 
	
	<p> In the code above, the variable <i>sigderivative</i> is also called the <i>sigmoid prime</i>(S') </p>
	
	Delta Output Sum = S'(O<sub>sum</sub>) * Output Sum Margin of Error <br>
	&Delta;<sub>sum</sub> = S'(1.233212) * -0.774380 <br>
	&Delta;<sub>sum</sub> = 0.174715 * -0.774380 <br>
	&Delta;<sub>sum</sub> =  -0.135296 <br> <br>
	
	&Delta;W = &Delta;<sub>sum</sub> / H<sub>out</sub> <br>
	&Delta;W<sub>1</sub> = &Delta;<sub>sum</sub> / H<sub>1 out</sub> <br>
	&Delta;W<sub>1</sub> = -0.135296 / 0.731059 <br>
	&Delta;W<sub>1</sub> = -0.185069 <br> <br>

	&Delta;W<sub>2</sub> = &Delta;<sub>sum</sub> / H<sub>2 out</sub> <br>
	&Delta;W<sub>2</sub> = -0.135296 / 0.785835 <br>
	&Delta;W<sub>2</sub> = -0.172168  <br> <br>
	
	&Delta;W<sub>3</sub> = &Delta;<sub>sum</sub> / H<sub>3 out</sub> <br>
	&Delta;W<sub>3</sub> = -0.135296 / 0.689974 <br>
	&Delta;W<sub>3</sub> = -0.196089  <br> <br>
	
	HW<sub>new</sub> = HW + &Delta;W
	HW<sub>1 new</sub> = HW<sub>1 old</sub> + &Delta;W<sub>1</sub> <br>
	HW<sub>1 new</sub> = 0.03 + -0.135296 <br>
	HW<sub>1 new</sub> = 0.105296 <br><br>
	
	HW<sub>2 new</sub> = HW<sub>2 old</sub> + &Delta;W<sub>2</sub> <br>
	HW<sub>2 new</sub> = 0.05 + -0.172168 <br>
	HW<sub>2 new</sub> = 0.122168   <br><br>

	HW<sub>3 new</sub> = HW<sub>3 old</sub> + &Delta;W<sub>3</sub> <br>
	HW<sub>3 new</sub> = 0.09 + -0.196089 <br>
	HW<sub>3 new</sub> = 0.106089   <br><br>
	
	(H<sub>1 out</sub> * HW<sub>1 old</sub>) * S'(I<sub>1</sub>) <br>
	(0.731059 * 0.3) * S'(1) <br>
	(0.731059 * 0.3) * 0.196612 <br>
	0.219318 * 0.196612 = 0.043121 <br>
	IW<sub>1 new</sub> = IW<sub>1 old</sub> - 0.043121 <br>
	IW<sub>1 new</sub> = 0.8 - 0.043121 = 0.756879 <br><br>
	
	(H<sub>2 out</sub> * HW<sub>2 old</sub>) * S'(I<sub>1</sub>) <br>
	(0.785835 * 0.4) * S'(1) <br>
	(0.785835 * 0.4) *  0.196612 <br>
	0.314334 * 0.785835 =  0.061802<br>
	IW<sub>2 new</sub> = IW<sub>2 old</sub> - 0.247015 <br>
	IW<sub>2 new</sub> = 0.4 - 0.061802 = 0.338198  <br><br>
	
	(H<sub>3 out</sub> * HW<sub>3 old</sub>) * S'(I<sub>1</sub>) <br>
	(0.689974 * 0.3) * S'(1) <br>
	(0.689974 * 0.3) *  0.196612 <br>
	0.206992 * 0.196612 =  0.040697 <br>
	IW<sub>3 new</sub> = IW<sub>3 old</sub> - 0.040697 <br>
	IW<sub>3 new</sub> = 0.3 - 0.040697 = 0.259303 <br><br>
	
	(H<sub>1 out</sub> * HW<sub>1 old</sub>) * S'(I<sub>2</sub>) <br>
	(0.731059 * 0.2) * S'(1) <br>
	(0.731059 * 0.2) * 0.196612 <br>
	0.146212 * 0.196612 = 0.028747 <br>
	IW<sub>4 new</sub> = IW<sub>4 old</sub> - 0.028747 <br>
	IW<sub>4 new</sub> = 0.2 - 0.028747 = 0.171253  <br><br>
	
	(H<sub>2 out</sub> * HW<sub>2 old</sub>) * S'(I<sub>2</sub>) <br>
	(0.785835 * 0.9) * S'(1) <br>
	(0.785835 * 0.9) *  0.196612 <br>
	0.707251 * 0.785835 =  0.555783 <br>
	IW<sub>5 new</sub> = IW<sub>5 old</sub> - 0.555783 <br>
	IW<sub>5 new</sub> = 0.9 - 0.555783 = 0.344217  <br><br>
	
	(H<sub>3 out</sub> * HW<sub>3 old</sub>) * S'(I<sub>2</sub>) <br>
	(0.689974 * 0.5) * S'(1) <br>
	(0.689974 * 0.5) *  0.196612 <br>
	0.344987 * 0.196612 =  0.067829 <br>
	IW<sub>6 new</sub> = IW<sub>6 old</sub> - 0.067829 <br>
	IW<sub>6 new</sub> = 0.5 - 0.067829 = 0.432171 <br><br>
	
	<p>
		<table border = 1> 
			<tr> <th> </th><th>Old</th> <th>New</th></tr>
			<tr> <td>IW<sub>1 </sub></td> <td> 0.8</td> <td>0.756879 </td></tr>
			<tr> <td> IW<sub>2</sub></td> <td>0.4 </td> <td> 0.338198 </td></tr>
			<tr> <td> IW<sub>3</sub> </td> <td> 0.3</td> <td> 0.259303</td></tr>
			<tr> <td> IW<sub>4 </sub></td> <td>0.2 </td> <td> 0.171253 </td></tr>
			<tr> <td> IW<sub>5</sub> </td> <td> 0.9</td> <td> 0.344217</td></tr>
			<tr> <td> IW<sub>6</sub></td> <td> 0.5</td> <td>0.432171 </td></tr>
			<tr> <td>HW<sub>1</sub> </td>  <td>0.3 </td> <td> 0.105296  </td></tr>
			<tr> <td> HW<sub>2</sub></td> <td> 0.5</td> <td> 0.122168  </td></tr>
			<tr> <td> HW<sub>3</sub></td> <td>0.9 </td> <td> 0.106089 </td></tr>
		</table>
	</p>
	Note how the larger numbers dropped more sugnificantly than the smaller numbers
	
	<p>	1 <i>epoch</i> = once through the training data <br><br>
	
	Two values that are decided at coding time are <br>	
	&epsilon; (epsilon) = Learning Rate = 0.7 <br>
	&alpha;	(alpha) = Momentum = 0.3 <br><br>
	
	These numbers are not concrete, but more trial and error to find the correct numbers. <br>
	If the network isn't converging (learning) then try lowering the learning rate (<i>epsilon</i>) <br>
	If the network  stops at a local minimum too often, try raising the <i>alpha</i> (momentum).  <i>Alpha</i> is a way (hopefully) to escape local minimumns.  
	Suppose the network has been decreasing gradients in an epoch, if it hit a sign that indicates the need to increase the gradient would indicate it has passed a 
	minimum, and needs to go back.
	This would be true if it just passed the <i>global</i> minimum.  If it just passed a <i>local</i> minimum, and continues decreasing the gradient for 
	(alpha or momentium) distance, hopefully it will be enough to escape the local minimum and continue to search for the global minimum.
	If the global minimum has just been passed, the network will back track after going (alpha or momentium) distance and assume it has passed the global minimum.
	This approach is known as <i>Online</i> training, adjusting the weights for each training set of data.
	</p>
	
	<p>If doing <i>batch</i> training, calculate the gradients for each weight and each input set.  
	Rather than changing the weights after each input set, keep a record of each training set error, average them, and make a weight change after each epoch.
	XOR has 4 distinct train sets (00, 10, 01,11).  A training set might contain 100 input pairs (in random order) and should have 25 of each type.  
	Keep a running count of all the 0,0 pair errors, average them, and make a weight change at the end of each epoch.
	</p>
	
</body>
</html>
